# Data Retrieval and Setup

In this section, we will cover the steps required for data retrieval and setup in the video indexing process. This is old code, TutorAI used similar code on a larger scale to get transcriptions of 18 courses which where used the legacy code was used for local testing.

1. **Gather the video data**: To gather the videos, a Webscraper was used. An old implementation can be found in `Datasetup/getmp3.py`. This file contains a function called `scrape_and_extract_audio(starturl)`. The `starturl` parameter should be an ISIS link ending with something like `course/COURSE#/browse`, where `COURSE#` is a 5-digit course code associated with a course. 

To use the script, follow these steps:
- Install the Chrome driver.
- install the imports
- Set the url to desired url
- Run the code
- Open the login page in the Chrome driver.
- Login using your TUB details.
- Click Enter in the terminal window where you started `getmp3.py`.

This script will save all the videos associated with that ISIS course as .mp3 files.

2. **Transcribe** U Ue command pipistal -U git+https://github.com/linto-ai/whisper-timestamped to nsall hisper timestamped. This is the main libray use togenerte timestamped transcriptions of the lectures. Change the audio path variable to the folder of which you want to transcribe the videos.

3. **Generate Embeddings** To do this look at the create vector json function in loadqdrant.py this function takes a folderpath and a course. This implementation is based on the data generated by tutorai. In their implementation they generate a download log with objects title and website. Title is formatted something along the lines course# video_number. Website is the link to the video on the isis website. It is assumed that the video with name title is in the folder course#. The commented out code in loadqdrant.py might be useful to look at to see how exactly this is done. By the end a list of course#.json files is generated with a list of timestamped transcriptions and their website. 

4**Loading into Qdrant** Use the quickstat documentation(https://qdrant.tech/documentation/quick-start/) to pull the dockerized version of qdrant. After running the container loading the data should be relatively easy look at the createcollection() function


# Running the Endpoint

To run the endpoint run fastapi_index.py you can test the enpoint with something like: curl -X POST "http://localhost:8047/vidindex/Was%20ist%20der%20unterschied%20zwischen%20NP%20und%20NP%20vollst%C3%A4ndig%3F" 
