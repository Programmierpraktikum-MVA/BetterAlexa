services:
        llama3_service:
                build:
                        context: ./server/function_calling
                container_name: betteralexa_llama_service
                ports:
                        - "8007:8007"
                deploy:
                        resources:
                                reservations:
                                        devices:
                                                - driver: nvidia
                                                  count: 1
                                                  capabilities: [gpu]

        microservices:
                build:
                        context: ./server/microservices
                container_name: betteralexa_microservices
                ports:
                        - "8006:8006"
